{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMH Data Insights Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "# Sign in into plotly in order to acces the API\n",
    "py.sign_in('aukintux', 'kHDm3kaUEo28gJcpnlfh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276348 entries, 0 to 276347\n",
      "Data columns (total 9 columns):\n",
      "PROMONAME    5684 non-null object\n",
      "Dealer       276348 non-null object\n",
      "mailaddr     276348 non-null object\n",
      "Ctrycode     272597 non-null object\n",
      "City         174277 non-null object\n",
      "Zipcode      119385 non-null object\n",
      "Itemname     276348 non-null object\n",
      "ROOMGROUP    274902 non-null object\n",
      "Regdate      276348 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read csv file with selected columns only\n",
    "df = pd.read_csv(\"data_bonus.csv\", usecols=[\"PROMONAME\", \"Dealer\", \"mailaddr\", \"Ctrycode\", \"City\", \"Zipcode\",\n",
    "                                      \"Itemname\", \"ROOMGROUP\", \"Regdate\"], \n",
    "                            dtype={\"PROMONAME\": object})\n",
    "# Save initial number of rows in dataframe\n",
    "initial_number_of_rows = df.shape[0]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 99.62% of the rows are still available for analysis. \n",
      "A 0.38% was removed due to 2017 year.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Promoname            object\n",
       "Dealer                 bool\n",
       "Mailaddr             object\n",
       "Ctrycode             object\n",
       "City                 object\n",
       "Zipcode              object\n",
       "Itemname             object\n",
       "Roomgroup            object\n",
       "Regdate      datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only rows where \"Ctrycode\" is defined\n",
    "df = df[df[\"Ctrycode\"] != \".\"]\n",
    "# Rename columns to make all column names capitalized\n",
    "df.rename(columns={\"PROMONAME\":\"Promoname\", \"mailaddr\": \"Mailaddr\", \"ROOMGROUP\": \"Roomgroup\"}, inplace=True)\n",
    "# Make \"Dealer\" column of type boolean\n",
    "bool_dic = {\"n\": False, \"y\": True}\n",
    "df.replace({\"Dealer\": bool_dic}, inplace=True)\n",
    "# Make \"Regdate\" column of type datetime\n",
    "df[\"Regdate\"] = pd.to_datetime(df[\"Regdate\"])\n",
    "df = df[~(df[\"Regdate\"].dt.year == 2017)]\n",
    "# Check how much of the initial data set rows are still left after the operation\n",
    "print(\"A {0:.2f}% of the rows are still available for analysis. \\nA {1:.2f}% was removed due to 2017 year.\".format(df.shape[0]*100/initial_number_of_rows, 100-df.shape[0]*100/initial_number_of_rows))\n",
    "# Print types of columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Promoname</th>\n",
       "      <th>Dealer</th>\n",
       "      <th>Mailaddr</th>\n",
       "      <th>Ctrycode</th>\n",
       "      <th>City</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Itemname</th>\n",
       "      <th>Roomgroup</th>\n",
       "      <th>Regdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Person1@shio.name</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEOS3</td>\n",
       "      <td>Speaker Name</td>\n",
       "      <td>2014-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Person1@shio.name</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEOS5</td>\n",
       "      <td>H5</td>\n",
       "      <td>2014-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Person1@shio.name</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEOS5</td>\n",
       "      <td>Heos 5 Hs</td>\n",
       "      <td>2014-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Person1@shio.name</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEOSLINK</td>\n",
       "      <td>Shio Mlink Hs1</td>\n",
       "      <td>2014-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Person2@shio.name</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEOS1HS2BK</td>\n",
       "      <td>Heos Link Hs2</td>\n",
       "      <td>2016-01-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Promoname Dealer           Mailaddr Ctrycode City Zipcode    Itemname  \\\n",
       "0       NaN  False  Person1@shio.name       JP  NaN     NaN       HEOS3   \n",
       "1       NaN  False  Person1@shio.name       JP  NaN     NaN       HEOS5   \n",
       "2       NaN  False  Person1@shio.name       JP  NaN     NaN       HEOS5   \n",
       "3       NaN  False  Person1@shio.name       JP  NaN     NaN    HEOSLINK   \n",
       "4       NaN  False  Person2@shio.name       JP  NaN     NaN  HEOS1HS2BK   \n",
       "\n",
       "        Roomgroup    Regdate  \n",
       "0    Speaker Name 2014-09-02  \n",
       "1              H5 2014-09-03  \n",
       "2       Heos 5 Hs 2014-09-02  \n",
       "3  Shio Mlink Hs1 2014-09-02  \n",
       "4   Heos Link Hs2 2016-01-28  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this section is to find out how is the behavior of weekly sales over time, check the importance of promocodes on the amount of sales and understand the distribution of daily sales per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dictionary of sections of the dataframe by year\n",
    "years = sorted(df[\"Regdate\"].dt.year.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we try to figure out how the behavior of sales varies over time, and at the same time what portion of sales are due to a promo code in order to see how effective is this marketing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/46.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create figure to plot in\n",
    "fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "\n",
    "# Get the date to plot, which is the number of sales per week for each year\n",
    "for i, year in enumerate(years):\n",
    "    year_df = df[df[\"Regdate\"].dt.year == year]\n",
    "    weeks_of_year = sorted(list(year_df[\"Regdate\"].dt.week.unique()))\n",
    "    sales_reg = []\n",
    "    weeks_promo = []\n",
    "    sales_promo = []\n",
    "    \n",
    "    # Go through each week of available data in the year and get promo sales and regular sales information\n",
    "    for week in weeks_of_year:\n",
    "        week_df = year_df[year_df[\"Regdate\"].dt.week == week]\n",
    "        sales = len(week_df)\n",
    "        promo_sales = len(week_df[~week_df[\"Promoname\"].isnull()])\n",
    "        sales_reg.append(sales-promo_sales)\n",
    "        if promo_sales > 0:\n",
    "            weeks_promo.append(week)\n",
    "            sales_promo.append(promo_sales)\n",
    "            \n",
    "    # Make and append traces to the figure\n",
    "    trace_regular = go.Bar(\n",
    "        x=weeks_of_year,\n",
    "        y=sales_reg,\n",
    "        marker=dict(\n",
    "            color='rgba(204,204,204,1)'\n",
    "        ),\n",
    "        name=\"Regular Sales\"\n",
    "    )\n",
    "    trace_promo = go.Bar(\n",
    "        x=weeks_promo,\n",
    "        y=sales_promo,\n",
    "        marker=dict(\n",
    "            color='rgb(49,130,189)'\n",
    "        ),\n",
    "        name=\"Promo Sales\"\n",
    "    )\n",
    "    fig.append_trace(trace_regular, 1, i+1)\n",
    "    fig.append_trace(trace_promo, 1, i+1)\n",
    "            \n",
    "# Plot figure\n",
    "fig['layout'].update(showlegend=False, barmode=\"stack\", title='Weekly Sales Per Year')\n",
    "py.iplot(fig, filename='weekly-sales-per-year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous graph we can see that promocode sales are almost negligible except for weeks 8 to 10 in 2015 and week 13 in the same year. It would be interesting to know if this effect is due to a single or multiple promocodes and which are responsible. It is also important to note that after this spike in sales the weekly average increased and stayed there for good even though that the amount of sales due to promocodes diminished. Meaning that the promocode reponsible for this spike had the long-lasting effect of increasing the weekly sales for good. Now, let us investigate which promocode was responsible for this spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/48.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create figure to plot in\n",
    "fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "\n",
    "# Add each subplot to the figure\n",
    "for i, year in enumerate(years):\n",
    "    year_df = df[df[\"Regdate\"].dt.year == year]\n",
    "    promo_year_df = year_df[[\"Promoname\", \"Regdate\"]].sort_values(\"Regdate\").dropna()\n",
    "    data = promo_year_df[\"Promoname\"].value_counts()\n",
    "    trace = go.Bar(\n",
    "        x=data.index,\n",
    "        y=data.values,\n",
    "        marker=dict(\n",
    "            color='rgb(49,130,189)'\n",
    "        ),\n",
    "        name=\"Sales\"\n",
    "    )\n",
    "    fig.append_trace(trace, 1, i+1)\n",
    "\n",
    "# Plot figure\n",
    "fig['layout'].update(showlegend=False, title='Promo Sales Per Year')\n",
    "py.iplot(fig, filename='promo-sales-per-year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the promocode SPOTIFY01 was the one responsible for the aforementioned spike in sales. It seems that since this promo had the long-lasting effect of increasing the sales weekly average one could argue that the major effect it had was to put the word out about the product and raise brand awareness. Now, let us investigate how has the distribution of sales changed across the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/50.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create figure to plot in\n",
    "fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "\n",
    "# Daily sales series\n",
    "daily_sales_series = df[\"Regdate\"].value_counts()\n",
    "\n",
    "# Add each subplot to the figure\n",
    "for i, year in enumerate(years):\n",
    "    trace = go.Histogram(\n",
    "        x=daily_sales_series[daily_sales_series.index.year == year],\n",
    "        name=\"Daily Sales\"\n",
    "    )\n",
    "    fig.append_trace(trace, 1, i+1)\n",
    "\n",
    "# Plot figure\n",
    "fig['layout'].update(showlegend=False, title='Daily Sales Histogram Per Year')\n",
    "py.iplot(fig, filename='daily-sales-histogram-per-year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2014 distribution has mean: 130.8116883116883 and standard deviation: 72.30309305956955\n",
      "--------------------\n",
      "The 2015 distribution has mean: 284.33972602739726 and standard deviation: 204.79109217820337\n",
      "--------------------\n",
      "The 2016 distribution has mean: 413.57377049180326 and standard deviation: 210.92195166583915\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    a = daily_sales_series[daily_sales_series.index.year == year]\n",
    "    print(\"The {0} distribution has mean: {1} and standard deviation: {2}\".format(year, np.mean(a), np.std(a)))\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the behavior of the distribution and how it has changed over time one reaches the following conclusions:\n",
    "\n",
    "1. The daily sales average has increased year after year showing the effects of the promocode SPOTIFY01.\n",
    "2. From 2015 to 2016 as well as registering an increase in daily sales average, the standard deviation decreased meaning the a bigger percentage of the sales are around this value. Providing the bussiness in better shape than in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generally understood how does the business behave, that promocode sales do not make up anymore a respresentative portion of sales even though it had a positive and lasting effect on sales. One would like to identify which countries are the ones that make up for the bulk of the sales in order to further investigate these markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get ISO-2 to ISO-3 country codes dictionary\n",
    "codes_df = pd.read_csv('https://raw.githubusercontent.com/datasets/country-codes/master/data/country-codes.csv')\n",
    "codes_df = codes_df[[\"ISO3166-1-Alpha-2\", \"ISO3166-1-Alpha-3\"]]\n",
    "codes_df.dropna(inplace=True)\n",
    "codes_df.columns = [\"ISO-2\", \"ISO-3\"]\n",
    "codes_df.set_index(\"ISO-2\", inplace=True)\n",
    "iso2_to_iso3_dict = codes_df.to_dict()[\"ISO-3\"]\n",
    "\n",
    "# Change country dataframe codes from ISO-2 to ISO-3 for plotly choropleth\n",
    "df_iso3 = df.replace({\"Ctrycode\": iso2_to_iso3_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def worldwide_sales_choropleth(year):\n",
    "    # Make sales by country dataframe\n",
    "    df_iso3_year = df_iso3[df_iso3[\"Regdate\"].dt.year == year]\n",
    "    ctry_data = df_iso3_year[\"Ctrycode\"].value_counts().astype(float)\n",
    "    ctry_data = ctry_data.reset_index()\n",
    "    ctry_data.columns = [\"Ctrycode\", \"Unitssold\"]\n",
    "\n",
    "    # Prepare data to plot dictionary\n",
    "    data = [dict(\n",
    "                type = 'choropleth',\n",
    "                locations = ctry_data['Ctrycode'],\n",
    "                z = ctry_data['Unitssold'],\n",
    "                colorscale = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n",
    "                    [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]],\n",
    "                autocolorscale = False,\n",
    "                reversescale = True,\n",
    "                marker = dict(\n",
    "                    line = dict (\n",
    "                        color = 'rgb(180,180,180)',\n",
    "                        width = 0.5\n",
    "                    ) ),\n",
    "                colorbar = dict(\n",
    "                    autotick = False,\n",
    "                    tickprefix = '',\n",
    "                    title = 'Units Sold')\n",
    "              )]\n",
    "\n",
    "    # Layout of plot\n",
    "    layout = dict(\n",
    "        title = \"Worldwide Sales {0}\".format(year),\n",
    "        geo = dict(\n",
    "            showframe = False,\n",
    "            showcoastlines = False,\n",
    "            projection = dict(\n",
    "                type = 'Mercator'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Actual plotting\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return py.iplot(fig, validate=False, filename='worldwide-sales-{0}'.format(year) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/52.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldwide_sales_choropleth(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/54.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldwide_sales_choropleth(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/56.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldwide_sales_choropleth(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 2016 Choropleth map we can see that the majority of sales come from: \n",
    "\n",
    "1. United States\n",
    "2. Netherlands\n",
    "3. Denmark\n",
    "4. Sweden\n",
    "5. Germany\n",
    "6. Norway\n",
    "7. Great Britain\n",
    "8. Australia\n",
    "9. Canada\n",
    "\n",
    "Then there is almost every major country in Europe with some considerable purchases and some come as well from China and Russia.\n",
    "\n",
    "Another important fact is that these countries are the one that most contribute to the sales every year since 2014. That is, the countries that constitute the bulk of the sales remain the same across the years and as such are characterized as stable markets. \n",
    "\n",
    "One could further sum up this list by saying that geographically the vast majority our customers are located in:\n",
    "\n",
    "1. North America\n",
    "2. The Scandinavian region\n",
    "3. [The 2 most powerful countries of Europe](https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=most%20powerful%20countries%20of%20europe) (Germany and Great Britain)\n",
    "4. Australia\n",
    "\n",
    "This way of paraphrasing the regions where the majority of sales come from illustrates the fact that the product is intended for a specific high-income audience. Now, exactly what portion of the sales come from these countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 80.74% of sales came from the aforementioned countries in 2014.\n",
      "--------------\n",
      "A 80.63% of sales came from the aforementioned countries in 2015.\n",
      "--------------\n",
      "A 79.61% of sales came from the aforementioned countries in 2016.\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "major_countries_codes = [\"US\", \"NL\", \"DK\", \"SE\", \"DE\", \"NO\", \"GB\", \"AU\", \"CA\"]\n",
    "for year in years:\n",
    "    year_df = df[df[\"Regdate\"].dt.year == year]\n",
    "    major_countries_purchases = len(year_df[year_df[\"Ctrycode\"].isin(major_countries_codes)])\n",
    "    all_purchases = len(year_df)\n",
    "    print(\"A {0:.2f}% of sales came from the aforementioned countries in {1}.\".format(major_countries_purchases*100/all_purchases, year))\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the major countries that make up 81% of our market one would like to further investigate these countries and see how the market within each has expanded over time differentiating at the same time which portion of the sales come from dealers and what portion comes from end-customers directly.\n",
    "\n",
    "** NOTE THAT WE MUST TAKE WEEKLY AVERAGES IN ORDER TO COMPARE SINCE THERE ARE WHOLE SECTIONS OF THE YEAR WITH MISSING DATA IN 2014 AND 2016 AND AVERAGING OVER THE AMOUNT OF WEEKS OF DATA AVAILABLE NORMALIZES IT. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/58.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create figure to plot in\n",
    "fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "    \n",
    "for i, year in enumerate(years):\n",
    "    year_df = df[df[\"Regdate\"].dt.year == year]\n",
    "    weeks_of_data = len(year_df[\"Regdate\"].dt.week.unique())\n",
    "    sales_dealer = []\n",
    "    sales_customer = []\n",
    "    for ctry_code in major_countries_codes:\n",
    "        ctry_df = year_df[year_df[\"Ctrycode\"] == ctry_code]\n",
    "        dealer_count = len(ctry_df[ctry_df[\"Dealer\"] == True])\n",
    "        sales_dealer.append(dealer_count/weeks_of_data)\n",
    "        sales_customer.append((len(ctry_df) - dealer_count)/weeks_of_data)\n",
    "    x_data = [x for x in major_countries_codes]\n",
    "    x_data.append(\"OTHERS\")\n",
    "    rest_world_df = year_df[~year_df[\"Ctrycode\"].isin(major_countries_codes)]\n",
    "    dealer_count = len(rest_world_df[rest_world_df[\"Dealer\"] == True])\n",
    "    sales_dealer.append(dealer_count/weeks_of_data)\n",
    "    sales_customer.append((len(rest_world_df) - dealer_count)/weeks_of_data)\n",
    "    \n",
    "    # Add each subplot to the figure\n",
    "    trace_dealer = go.Bar(\n",
    "        x=x_data,\n",
    "        y=sales_dealer,\n",
    "        marker=dict(\n",
    "            color='rgba(204,204,204,1)'\n",
    "        ),\n",
    "        name=\"Dealer Sales\"\n",
    "    )\n",
    "    trace_customer = go.Bar(\n",
    "        x=x_data,\n",
    "        y=sales_customer,\n",
    "        marker=dict(\n",
    "            color='rgb(49,130,189)'\n",
    "        ),\n",
    "        name=\"Customer Sales\"\n",
    "    )\n",
    "    fig.append_trace(trace_dealer, 1, i+1)\n",
    "    fig.append_trace(trace_customer, 1, i+1)\n",
    "\n",
    "\n",
    "# Plot figure\n",
    "fig['layout'].update(showlegend=False, barmode=\"stack\", title='Weekly Average Country Sales per Year')\n",
    "py.iplot(fig, filename='weekly-average-country-sales-per-year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the evolution of sales on a year on year basis one can see that sales have increased in almost every major country. More specifically:\n",
    "\n",
    "1. The US has maintained as the biggest single purchasing country with sales doubling from 2014 to 2015 where they have stayed ever since, meaning that the company has reached market saturation under its current constraints. That is. Under the campaigns, promotions and methods that is currently using. In order to further expand one would need to try different marketing efforts.\n",
    "2. All other major markets have seen as well great expansion. Expanding from 1.5 times to 3 times (as is the case of Netherlands). The only has been exception of Canada which has remained approximately the same in size. One would assume that due to the geographic and cultural similarity with the US (meaning that US-CA are more culturally similar than say NL-US or DE-US) it should have expanded more significatively. This poses the question as to what marketing efforts have been made in the region and if such efforts should be further expanded to reach the full market potential.\n",
    "4. It is also interesting to see that the biggest portion of the sales by far come from end-customers directly. This means that online marketing efforts preferably geo-localized are in order as this could boost sales. e.g. SEO Optimization - Facebook Advertising - Other kinds of network advertising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2014 to 2016\n",
      "US has expanded 2.8 times.\n",
      "NL has expanded 6.2 times.\n",
      "DK has expanded 2.1 times.\n",
      "SE has expanded 2.6 times.\n",
      "DE has expanded 3.8 times.\n",
      "NO has expanded 3.0 times.\n",
      "GB has expanded 2.9 times.\n",
      "AU has expanded 6.0 times.\n",
      "CA has expanded 2.2 times.\n"
     ]
    }
   ],
   "source": [
    "first_year_df = df[df[\"Regdate\"].dt.year == years[0]]\n",
    "last_year_df = df[df[\"Regdate\"].dt.year == years[len(years)-1]]\n",
    "\n",
    "first_year_number_of_weeks = len(first_year_df[\"Regdate\"].dt.week.unique())\n",
    "last_year_number_of_weeks = len(last_year_df[\"Regdate\"].dt.week.unique())\n",
    "    \n",
    "print(\"From {0} to {1}\".format(years[0], years[len(years)-1]))\n",
    "\n",
    "for ctry_code in major_countries_codes:\n",
    "    last_year_weekly_avg = len(last_year_df[last_year_df[\"Ctrycode\"] == ctry_code]) / last_year_number_of_weeks\n",
    "    first_year_weekly_avg = len(first_year_df[first_year_df[\"Ctrycode\"] == ctry_code]) / first_year_number_of_weeks\n",
    "    kappa = last_year_weekly_avg / first_year_weekly_avg\n",
    "    print(\"{0} has expanded {1:.1f} times.\".format(ctry_code, kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having identified the major countries one would like to go deeper by understanding each of these major markets. The following analysis takes as example the US since it is the biggest buyer from the major countries. However to analyze a different country simply change the ISO-2 country code and runn the cells bellow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Rember as well that these values must be weekly averages in order to compare year on year. This is so, because 2014 and 2016 have whole months where data is missing. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctry_code_to_analyze = \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_country_sales_per_year(country_code):\n",
    "    fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "    for i, year in enumerate(years):\n",
    "        country_df = df[(df[\"Ctrycode\"] == country_code) & (df[\"Regdate\"].dt.year == year)]\n",
    "        types_of_product = country_df[\"Itemname\"].value_counts().index\n",
    "        weeks_of_data = len(country_df[\"Regdate\"].dt.week.unique())\n",
    "        sales_customer = []\n",
    "        sales_dealer = []\n",
    "        for product in types_of_product:\n",
    "            product_df = country_df[country_df[\"Itemname\"] == product]\n",
    "            dealer_count = len(product_df[product_df[\"Dealer\"] == True])\n",
    "            sales_dealer.append(dealer_count/weeks_of_data)\n",
    "            sales_customer.append((len(product_df) - dealer_count)/weeks_of_data)\n",
    "        # Add each subplot to the figure\n",
    "        trace_dealer = go.Bar(\n",
    "            x=types_of_product,\n",
    "            y=sales_dealer,\n",
    "            marker=dict(\n",
    "                color='rgba(204,204,204,1)'\n",
    "            ),\n",
    "            name=\"Dealer Sales\"\n",
    "        )\n",
    "        trace_customer = go.Bar(\n",
    "            x=types_of_product,\n",
    "            y=sales_customer,\n",
    "            marker=dict(\n",
    "                color='rgb(49,130,189)'\n",
    "            ),\n",
    "            name=\"Customer Sales\"\n",
    "        )\n",
    "        fig.append_trace(trace_dealer, 1, i+1)\n",
    "        fig.append_trace(trace_customer, 1, i+1)\n",
    "    # Plot figure\n",
    "    fig['layout'].update(showlegend=False, barmode=\"stack\", title='Weekly Average {0} Sales by Product per Year'.format(country_code))\n",
    "    return py.iplot(fig, filename=\"weekly-average-sales-by-product-per-year-{0}\".format(country_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/60.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_country_sales_per_year(ctry_code_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can reach the following conclusions:\n",
    "\n",
    "1. From 2014 to 2015 more products apparently where added and the overall sales increased. However from 2015 to 2016 the sales spread out across products. This means that the optimum number of products to maximize sales has been reached and surpassed.\n",
    "2. More products should not be added to the catalog if one does not wishes to see that sales spread out more across different products. Perhaps a replacement of products would be more suitable or a reduction if at all possible.\n",
    "\n",
    "Let us further investigate this claim that the sales spread out across products instead of adding up. In order to do this let us see how many products does a user buys in a single purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_products_by_sale(country_code):\n",
    "    \n",
    "    fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        year_df = df[(df[\"Regdate\"].dt.year == year) & (df[\"Ctrycode\"] == country_code) & (df[\"Dealer\"] == False)]\n",
    "        \n",
    "        products_by_sale_histogram = []\n",
    "        emails = year_df[\"Mailaddr\"].unique()\n",
    "        for email in emails:\n",
    "            email_df = year_df[year_df[\"Mailaddr\"] == email]\n",
    "            number_of_products_per_single_purchase = email_df[\"Regdate\"].value_counts()\n",
    "            products_by_sale_histogram = products_by_sale_histogram + list(number_of_products_per_single_purchase.values)\n",
    "            \n",
    "        trace = go.Histogram(\n",
    "            x=products_by_sale_histogram,\n",
    "            name=\"Number of Products per Single Purchase\"\n",
    "        )\n",
    "        fig.append_trace(trace, 1, i+1)\n",
    "\n",
    "        \n",
    "    # Plot figure\n",
    "    fig['layout'].update(showlegend=False, barmode=\"stack\", title='Number of Products per Single Purchase - {0}'.format(country_code))\n",
    "    return py.iplot(fig, filename=\"products-per-single-purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/66.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_products_by_sale(ctry_code_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can indeed check from the previous histograms that the majority of customers buy a single product per purchase causing the sales to spread out across the different product types. Now, the next natural question is: * Within these countries which cities make up for most of the sales? *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cities_by_country(country_code):\n",
    "    \n",
    "    # First n rooms to plot\n",
    "    first_n = 5\n",
    "    \n",
    "    fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        year_df = df[(df[\"Regdate\"].dt.year == year) & (df[\"Ctrycode\"] == country_code)]\n",
    "        weeks_of_data = len(year_df[\"Regdate\"].dt.week.unique())\n",
    "        city_counts = year_df[\"City\"].value_counts() / weeks_of_data\n",
    "        principal_cities = city_counts[0:first_n]\n",
    "        \n",
    "        trace = go.Bar(\n",
    "            x=principal_cities.index,\n",
    "            y=principal_cities.values,\n",
    "            marker=dict(\n",
    "                color='rgb(49,130,189)'\n",
    "            ),\n",
    "            name=\"City Sales\"\n",
    "        )\n",
    "        fig.append_trace(trace, 1, i+1)\n",
    "        \n",
    "    # Plot figure\n",
    "    fig['layout'].update(showlegend=False, barmode=\"stack\", title='Weekly Average {0} City Sales Per Year'.format(country_code))\n",
    "    return py.iplot(fig, filename=\"weekly-average-city-sales-per-year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/64.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_cities_by_country(ctry_code_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sees that cities change over time, even though Houston, Liverpool, Austin appear more than once. This could be due to a still changing market within the country or due to the missing gaps of data in 2014 and 2016. In this case geolocalization of Facebook Ads and SEO Otimization on Google and Bing with a country level scope would be more suitable in order not to neglect any counties or regions within the country that could be potentially good and stable markets.\n",
    "\n",
    "Lastly, it would be also interesting to see what is the intended use of the product in each country in order to tailor the marking ad copy according to it. That is, to see if the customer buys the product with the intention of using it with friends and family or having it for personal use mainly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_roomname_by_country(country_code):\n",
    "    # First n rooms to plot\n",
    "    first_n = 5\n",
    "\n",
    "    fig = tools.make_subplots(rows=1, cols=len(years), subplot_titles=tuple(years), shared_yaxes=True)\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        year_df = df[(df[\"Regdate\"].dt.year == year) & (df[\"Ctrycode\"] == country_code)]\n",
    "        roomgroup_counts = year_df[\"Roomgroup\"].value_counts()\n",
    "        principal_roomgroups = roomgroup_counts[0:first_n]\n",
    "        trace = go.Bar(\n",
    "            x=principal_roomgroups.index,\n",
    "            y=principal_roomgroups.values,\n",
    "            marker=dict(\n",
    "                color='rgb(49,130,189)'\n",
    "            ),\n",
    "            name=\"Roomname Use\"\n",
    "        )\n",
    "        fig.append_trace(trace, 1, i+1)\n",
    "\n",
    "    # Plot figure\n",
    "    fig['layout'].update(showlegend=False, barmode=\"stack\", title='Room Use in {0}'.format(country_code))\n",
    "    return py.iplot(fig, filename=\"roomgroup-per-year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~aukintux/44.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plots 5 more popular rooms by country\n",
    "plot_roomname_by_country(ctry_code_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sees that a big portion of the users set up their sound system in common rooms i.e. anything that is not the Bedroom is considered a common room. As: Main Room, Outdoor, Speaker Name and Kitchen. With the most popular use case being the \"Main room\", this indicates that:\n",
    "\n",
    "1. The products are mostly intended for group use not for personal use exclusively.\n",
    "\n",
    "Wich in turn is an actionable conclusion since one could:\n",
    "\n",
    "1. Make the App that controls the sound system more group engaging. Adding features like group playlists where each user in the room could add a different song to the playlist making it a Crowdsourced experience.\n",
    "2. Focus the marketing material such that in the scene or ad-copy people appear among friends and family. This way the end-customer can relate more closely to the experience of having the product since this the intended use case which in turn gives the company an edge by apealing to the customer emotions producing a posible increase in sales. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
